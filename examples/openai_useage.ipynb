{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"src\"), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GeminiCompressor' from 'src.compression.gemini' (/Users/amirdor/Documents/LLMOpt/src/compression/gemini.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_selector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_registry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelRegistry, ModelConfig\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenaiCompressor\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemini\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiCompressor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_selector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproviders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIProvider\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_selector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproviders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemini\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiProvider\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GeminiCompressor' from 'src.compression.gemini' (/Users/amirdor/Documents/LLMOpt/src/compression/gemini.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.llm_selector.core import LLMSelector\n",
    "from src.config.settings import ModelConfig, DynamicLLMSelectorConfig\n",
    "from src.llm_selector.model_registry import ModelRegistry, ModelConfig\n",
    "from src.compression.openai import OpenaiCompressor\n",
    "from src.compression.gemini import GeminiCompressor\n",
    "from src.llm_selector.providers.openai import OpenAIProvider\n",
    "from src.llm_selector.providers.gemini import GeminiProvider\n",
    "from src.llm_selector.providers.anthropic import AnthropicProvider\n",
    "from src.complextiy.gemini import GeminiComplexityAnalyzer\n",
    "from src.complextiy.code import CodeComplexityAnalyzer\n",
    "from src.compression.code import CodeCompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "compressor = OpenaiCompressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from typing import Dict, Any\n",
    "\n",
    "def load_yaml_files(directory: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load all YAML files from a given directory and return a unified dictionary.\n",
    "    \n",
    "    :param directory: Path to the directory containing YAML files.\n",
    "    :return: A dictionary containing the merged content of all YAML files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "    \n",
    "    unified_data = {}\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".yaml\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as yaml_file:\n",
    "                    try:\n",
    "                        # Load the content of the YAML file\n",
    "                        data = yaml.safe_load(yaml_file)\n",
    "                        if isinstance(data, dict):\n",
    "                            # Merge the loaded data into the unified dictionary\n",
    "                            unified_data.update(data)\n",
    "                        else:\n",
    "                            print(f\"Skipping {file_path}: Root element is not a dictionary.\")\n",
    "                    except yaml.YAMLError as e:\n",
    "                        print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    return unified_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openai_pricing': {'gpt_3_5_turbo': {'input': 0.0005, 'output': 0.0015}, 'gpt_3_5_turbo_16k': {'input': 0.003, 'output': 0.006}, 'gpt_4': {'input': 0.01, 'output': 0.03}, 'gpt_4_32k': {'input': 0.03, 'output': 0.06}, 'gpt_4o': {'input': 0.0025, 'output': 0.01}, 'gpt_4o_mini': {'input': 0.00015, 'output': 0.0006}, 'gpt_4_turbo': {'input': 0.01, 'output': 0.03}, 'o1': {'input': 0.015, 'output': 0.06}, 'o1_mini': {'input': 0.003, 'output': 0.012}, 'gpt_4o_realtime_preview': {'input': 0.005, 'output': 0.02}, 'gpt_4o_mini_realtime_preview': {'input': 0.0006, 'output': 0.0024}}, 'anthropic_pricing': {'claude_3_5_sonnet': {'context_window': 200000, 'input_cost_per_mtok': 3.0, 'output_cost_per_mtok': 15.0, 'prompt_caching_write': 3.75, 'prompt_caching_read': 0.3, 'notes': 'Most intelligent model, 50% discount with Batches API'}, 'claude_3_5_haiku': {'context_window': 200000, 'input_cost_per_mtok': 0.8, 'output_cost_per_mtok': 4.0, 'prompt_caching_write': 1.0, 'prompt_caching_read': 0.08, 'notes': 'Fastest and most cost-effective model, 50% discount with Batches API'}, 'claude_3_opus': {'context_window': 200000, 'input_cost_per_mtok': 15.0, 'output_cost_per_mtok': 75.0, 'prompt_caching_write': 18.75, 'prompt_caching_read': 1.5, 'notes': 'Powerful model for complex tasks, 50% discount with Batches API'}}, 'gemini_pricing': {'gemini_1_5_flash': {'input_pricing': {'below_128k': 0.075, 'above_128k': 0.15}, 'output_pricing': {'below_128k': 0.3, 'above_128k': 0.6}}, 'gemini_1_5_flash_8b': {'input_pricing': {'below_128k': 0.0375, 'above_128k': 0.075}, 'output_pricing': {'below_128k': 0.15, 'above_128k': 0.3}}, 'gemini_1_5_pro': {'input_pricing': {'below_128k': 1.25, 'above_128k': 2.5}, 'output_pricing': {'below_128k': 5.0, 'above_128k': 10.0}}, 'gemini_1_0_pro': {'input_pricing': {'below_128k': 0.5, 'above_128k': 1.0}, 'output_pricing': {'below_128k': 1.5, 'above_128k': 3.0}}}}\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the YAML files\n",
    "directory = \"../src/config/pricing/\"\n",
    "\n",
    "# Load all YAML files\n",
    "all_pricing_data = load_yaml_files(directory)\n",
    "\n",
    "# Print the unified dictionary\n",
    "print(all_pricing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration\n",
    "custom_config = DynamicLLMSelectorConfig(\n",
    "    models={\n",
    "        # Gemini models\n",
    "        \"gemini-1.5-flash\": ModelConfig(\n",
    "            name=\"gemini-1.5-flash\",\n",
    "            provider=\"gemini\",\n",
    "            complexity_threshold=20.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash\"][\"input_pricing\"][\"below_128k\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash\"][\"output_pricing\"][\"below_128k\"],\n",
    "            model_instance=GeminiProvider(\"gemini-1.5-flash\")\n",
    "        ),\n",
    "        \"gemini-1.5-flash-8b\": ModelConfig(\n",
    "            name=\"gemini-1.5-flash-8b\",\n",
    "            provider=\"gemini\",\n",
    "            complexity_threshold=10.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash_8b\"][\"input_pricing\"][\"below_128k\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash_8b\"][\"output_pricing\"][\"below_128k\"],\n",
    "            model_instance=GeminiProvider(\"gemini-1.5-flash-8b\")\n",
    "        ),\n",
    "        # \"gemini-1.5-pro\": ModelConfig(\n",
    "        #     name=\"gemini-1.5-pro\",\n",
    "        #     provider=\"gemini\",\n",
    "        #     complexity_threshold=50.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_pro\"][\"input_pricing\"][\"below_128k\"],\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_pro\"][\"output_pricing\"][\"below_128k\"],\n",
    "        #     model_instance=GeminiProvider(\"gemini-1.5-pro\")\n",
    "        # ),\n",
    "\n",
    "        # OpenAI models\n",
    "        \"gpt-3.5-turbo\": ModelConfig(\n",
    "            name=\"gpt-3.5-turbo\",\n",
    "            provider=\"openai\",\n",
    "            complexity_threshold=40.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_3_5_turbo\"][\"input\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_3_5_turbo\"][\"output\"],\n",
    "            model_instance=OpenAIProvider(\"gpt-3.5-turbo\")\n",
    "        ),\n",
    "        \"gpt-4o-mini\": ModelConfig(\n",
    "            name=\"gpt-4o-mini\",\n",
    "            provider=\"openai\",\n",
    "            complexity_threshold=55.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_4o_mini\"][\"input\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_4o_mini\"][\"output\"],\n",
    "            model_instance=OpenAIProvider(\"gpt-4o-mini\")\n",
    "        ),\n",
    "        \"gpt-4\": ModelConfig(\n",
    "            name=\"gpt-4\",\n",
    "            provider=\"openai\",\n",
    "            complexity_threshold=75.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_4\"][\"input\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_4\"][\"output\"],\n",
    "            model_instance=OpenAIProvider(\"gpt-4\")\n",
    "        ),\n",
    "        # \"gpt-4-turbo\": ModelConfig(\n",
    "        #     name=\"gpt-4-turbo\",\n",
    "        #     provider=\"openai\",\n",
    "        #     complexity_threshold=80.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_4_turbo\"][\"input\"],\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_4_turbo\"][\"output\"],\n",
    "        #     model_instance=OpenAIProvider(\"gpt-4-turbo\")\n",
    "        # ),\n",
    "\n",
    "        # # Anthropic models\n",
    "        # \"claude-3.5-sonnet\": ModelConfig(\n",
    "        #     name=\"claude-3.5-sonnet\",\n",
    "        #     provider=\"anthropic\",\n",
    "        #     complexity_threshold=60.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_sonnet\"][\"input_cost_per_mtok\"] / 1000,\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_sonnet\"][\"output_cost_per_mtok\"] / 1000,\n",
    "        #     model_instance=AnthropicProvider(\"claude-3.5-sonnet\")\n",
    "        # ),\n",
    "        # \"claude-3.5-haiku\": ModelConfig(\n",
    "        #     name=\"claude-3.5-haiku\",\n",
    "        #     provider=\"anthropic\",\n",
    "        #     complexity_threshold=45.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_haiku\"][\"input_cost_per_mtok\"] / 1000,\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_haiku\"][\"output_cost_per_mtok\"] / 1000,\n",
    "        #     model_instance=AnthropicProvider(\"claude-3.5-haiku\")\n",
    "        # ),\n",
    "        # \"claude-3-opus\": ModelConfig(\n",
    "        #     name=\"claude-3-opus\",\n",
    "        #     provider=\"anthropic\",\n",
    "        #     complexity_threshold=85.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"anthropic_pricing\"][\"claude_3_opus\"][\"input_cost_per_mtok\"] / 1000,\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"anthropic_pricing\"][\"claude_3_opus\"][\"output_cost_per_mtok\"] / 1000,\n",
    "        #     model_instance=AnthropicProvider(\"claude-3-opus\")\n",
    "        # )\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model registry\n",
    "model_registry = ModelRegistry()\n",
    "model_registry.register_models(custom_config.get_models_for_registry())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelConfig(name='gemini-1.5-flash-8b', provider='gemini', complexity_threshold=10.0, cost_per_1k_tokens_input=0.0375, cost_per_1k_tokens_output=0.15, api_key=None, model_instance=<src.llm_selector.providers.gemini.GeminiProvider object at 0x166dd2920>),\n",
       " ModelConfig(name='gemini-1.5-flash', provider='gemini', complexity_threshold=20.0, cost_per_1k_tokens_input=0.075, cost_per_1k_tokens_output=0.3, api_key=None, model_instance=<src.llm_selector.providers.gemini.GeminiProvider object at 0x166dd1fc0>),\n",
       " ModelConfig(name='gpt-3.5-turbo', provider='openai', complexity_threshold=40.0, cost_per_1k_tokens_input=0.0005, cost_per_1k_tokens_output=0.0015, api_key='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', model_instance=<src.llm_selector.providers.openai.OpenAIProvider object at 0x166dd2980>),\n",
       " ModelConfig(name='gpt-4o-mini', provider='openai', complexity_threshold=55.0, cost_per_1k_tokens_input=0.00015, cost_per_1k_tokens_output=0.0006, api_key='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', model_instance=<src.llm_selector.providers.openai.OpenAIProvider object at 0x166dd3970>),\n",
       " ModelConfig(name='gpt-4', provider='openai', complexity_threshold=75.0, cost_per_1k_tokens_input=0.01, cost_per_1k_tokens_output=0.03, api_key='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', model_instance=<src.llm_selector.providers.openai.OpenAIProvider object at 0x166dd3f10>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_registry.get_sorted_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM Selector with custom configuration\n",
    "llm_selector = LLMSelector(model_registry=model_registry, compression=compressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex prompts with varying complexity\n",
    "prompts = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Explain the basics of machine learning\",\n",
    "    \"Provide a comprehensive analysis of quantum computing's impact on cryptography\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 20:54:47,329 - INFO - Prompt complexity: 10.208825906469123\n",
      "2025-01-24 20:54:47,330 - INFO - Selected model: gemini-1.5-flash\n",
      "2025-01-24 20:54:47,330 - INFO - Prompt complexity: 10.208825906469123\n",
      "2025-01-24 20:54:47,330 - INFO - Selected model: gemini-1.5-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Hello, how are you?\n",
      "Complexity Details: {'prompt': 'Hello, how are you?', 'complexity_score': 10.208825906469123, 'selected_model': 'gemini-1.5-flash', 'details': {'overall_complexity': 10.208825906469123, 'token_complexity': 41.53677461028802, 'linguistic_complexity': 0.0, 'structural_complexity': 2, 'token_count': 6}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 20:54:50,093 - INFO - Response generated using gemini-1.5-flash, response: {'response': 'I am doing well, thank you for asking!  How are you today?\\n', 'usage': {'input_tokens': 7, 'output_tokens': 17, 'total_tokens': 24}}\n",
      "2025-01-24 20:54:50,095 - INFO - Added input cost: $0.0005, output cost: $0.0051, total: $0.0056. Running total: input $0.0005, output $0.0051, total $0.0056\n",
      "2025-01-24 20:54:50,097 - INFO - Prompt complexity: 15.773579999999995\n",
      "2025-01-24 20:54:50,098 - INFO - Selected model: gemini-1.5-flash\n",
      "2025-01-24 20:54:50,100 - INFO - Prompt complexity: 15.773579999999995\n",
      "2025-01-24 20:54:50,101 - INFO - Selected model: gemini-1.5-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I am doing well, thank you for asking!  How are you today?\n",
      "\n",
      "\n",
      "Prompt: Explain the basics of machine learning\n",
      "Complexity Details: {'prompt': 'Explain the basics of machine learning', 'complexity_score': 15.773579999999995, 'selected_model': 'gemini-1.5-flash', 'details': {'overall_complexity': 15.773579999999995, 'token_complexity': 52.285714285714285, 'linguistic_complexity': 3.0484999999999927, 'structural_complexity': 2, 'token_count': 7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 20:54:56,513 - INFO - Response generated using gemini-1.5-flash, response: {'response': 'Machine learning (ML) is a branch of artificial intelligence (AI) that focuses on enabling computer systems to learn from data without being explicitly programmed.  Instead of relying on hard-coded rules, ML algorithms identify patterns, make predictions, and improve their performance over time based on the data they are exposed to.\\n\\nHere\\'s a breakdown of the basics:\\n\\n**1. Core Idea: Learning from Data**\\n\\nThe fundamental principle is that machines can learn from data, just like humans do.  This learning process allows them to perform tasks without specific instructions for every scenario.  For example, instead of programming a system to recognize a cat in every possible image, you feed it thousands of cat images and let it learn the features that define a cat.\\n\\n**2. Types of Machine Learning:**\\n\\nThere are three main categories of ML:\\n\\n* **Supervised Learning:** The algorithm is trained on a labeled dataset.  This means the data includes both the input features and the desired output (the \"label\").  The algorithm learns to map inputs to outputs. Examples include:\\n    * **Regression:** Predicting a continuous value (e.g., house price prediction).\\n    * **Classification:** Predicting a categorical value (e.g., spam detection, image classification).\\n\\n* **Unsupervised Learning:** The algorithm is trained on an unlabeled dataset.  It aims to discover hidden patterns and structures in the data without any predefined output. Examples include:\\n    * **Clustering:** Grouping similar data points together (e.g., customer segmentation).\\n    * **Dimensionality Reduction:** Reducing the number of variables while preserving important information (e.g., feature extraction).\\n\\n* **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment.  It receives rewards for good actions and penalties for bad actions, learning to maximize its cumulative reward. Examples include:\\n    * **Game playing:**  Training an AI to play games like chess or Go.\\n    * **Robotics:** Training robots to perform complex tasks.\\n\\n\\n**3. Key Components:**\\n\\n* **Data:** The fuel for machine learning.  The quality and quantity of data significantly impact the performance of the algorithm.\\n* **Algorithm:** The set of rules and calculations used to learn from the data.  Different algorithms are suited to different types of problems and data.\\n* **Model:** The output of the learning process.  It represents the learned patterns and can be used to make predictions on new, unseen data.\\n* **Evaluation:** Assessing the performance of the model using metrics relevant to the task (e.g., accuracy, precision, recall).\\n\\n\\n**4. Simple Example (Supervised Learning):**\\n\\nImagine you want to predict a person\\'s weight based on their height.  You have a dataset of people\\'s heights and weights.  A supervised learning algorithm (e.g., linear regression) would learn the relationship between height and weight from this data.  Once trained, it can then predict the weight of a new person given their height.\\n\\n\\n**5.  Limitations:**\\n\\n* **Data bias:**  If the training data is biased, the model will likely be biased as well.\\n* **Overfitting:**  The model learns the training data too well and performs poorly on unseen data.\\n* **Interpretability:**  Some complex models are difficult to understand, making it hard to debug or explain their predictions.\\n\\n\\nMachine learning is a vast and evolving field, but these basics provide a foundational understanding of its core concepts and principles.  Each type of learning and algorithm has its own nuances and complexities, but the overarching goal remains the same: to enable computers to learn from data and improve their performance over time.\\n', 'usage': {'input_tokens': 7, 'output_tokens': 760, 'total_tokens': 767}}\n",
      "2025-01-24 20:54:56,514 - INFO - Added input cost: $0.0005, output cost: $0.2280, total: $0.2285. Running total: input $0.0010, output $0.2331, total $0.2341\n",
      "2025-01-24 20:54:56,517 - INFO - Prompt complexity: 44.4812340923514\n",
      "2025-01-24 20:54:56,518 - INFO - Selected model: gpt-4o-mini\n",
      "2025-01-24 20:54:56,520 - INFO - Prompt complexity: 44.4812340923514\n",
      "2025-01-24 20:54:56,520 - INFO - Selected model: gpt-4o-mini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Machine learning (ML) is a branch of artificial intelligence (AI) that focuses on enabling computer systems to learn from data without being explicitly programmed.  Instead of relying on hard-coded rules, ML algorithms identify patterns, make predictions, and improve their performance over time based on the data they are exposed to.\n",
      "\n",
      "Here's a breakdown of the basics:\n",
      "\n",
      "**1. Core Idea: Learning from Data**\n",
      "\n",
      "The fundamental principle is that machines can learn from data, just like humans do.  This learning process allows them to perform tasks without specific instructions for every scenario.  For example, instead of programming a system to recognize a cat in every possible image, you feed it thousands of cat images and let it learn the features that define a cat.\n",
      "\n",
      "**2. Types of Machine Learning:**\n",
      "\n",
      "There are three main categories of ML:\n",
      "\n",
      "* **Supervised Learning:** The algorithm is trained on a labeled dataset.  This means the data includes both the input features and the desired output (the \"label\").  The algorithm learns to map inputs to outputs. Examples include:\n",
      "    * **Regression:** Predicting a continuous value (e.g., house price prediction).\n",
      "    * **Classification:** Predicting a categorical value (e.g., spam detection, image classification).\n",
      "\n",
      "* **Unsupervised Learning:** The algorithm is trained on an unlabeled dataset.  It aims to discover hidden patterns and structures in the data without any predefined output. Examples include:\n",
      "    * **Clustering:** Grouping similar data points together (e.g., customer segmentation).\n",
      "    * **Dimensionality Reduction:** Reducing the number of variables while preserving important information (e.g., feature extraction).\n",
      "\n",
      "* **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment.  It receives rewards for good actions and penalties for bad actions, learning to maximize its cumulative reward. Examples include:\n",
      "    * **Game playing:**  Training an AI to play games like chess or Go.\n",
      "    * **Robotics:** Training robots to perform complex tasks.\n",
      "\n",
      "\n",
      "**3. Key Components:**\n",
      "\n",
      "* **Data:** The fuel for machine learning.  The quality and quantity of data significantly impact the performance of the algorithm.\n",
      "* **Algorithm:** The set of rules and calculations used to learn from the data.  Different algorithms are suited to different types of problems and data.\n",
      "* **Model:** The output of the learning process.  It represents the learned patterns and can be used to make predictions on new, unseen data.\n",
      "* **Evaluation:** Assessing the performance of the model using metrics relevant to the task (e.g., accuracy, precision, recall).\n",
      "\n",
      "\n",
      "**4. Simple Example (Supervised Learning):**\n",
      "\n",
      "Imagine you want to predict a person's weight based on their height.  You have a dataset of people's heights and weights.  A supervised learning algorithm (e.g., linear regression) would learn the relationship between height and weight from this data.  Once trained, it can then predict the weight of a new person given their height.\n",
      "\n",
      "\n",
      "**5.  Limitations:**\n",
      "\n",
      "* **Data bias:**  If the training data is biased, the model will likely be biased as well.\n",
      "* **Overfitting:**  The model learns the training data too well and performs poorly on unseen data.\n",
      "* **Interpretability:**  Some complex models are difficult to understand, making it hard to debug or explain their predictions.\n",
      "\n",
      "\n",
      "Machine learning is a vast and evolving field, but these basics provide a foundational understanding of its core concepts and principles.  Each type of learning and algorithm has its own nuances and complexities, but the overarching goal remains the same: to enable computers to learn from data and improve their performance over time.\n",
      "\n",
      "\n",
      "Prompt: Provide a comprehensive analysis of quantum computing's impact on cryptography\n",
      "Complexity Details: {'prompt': \"Provide a comprehensive analysis of quantum computing's impact on cryptography\", 'complexity_score': 44.4812340923514, 'selected_model': 'gpt-4o-mini', 'details': {'overall_complexity': 44.4812340923514, 'token_complexity': 72.19753977633306, 'linguistic_complexity': 38.00554545454544, 'structural_complexity': 2, 'token_count': 11}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 20:55:10,044 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-01-24 20:55:10,049 - INFO - Response generated using gpt-4o-mini, response: {'response': \"Quantum computing is poised to have a profound impact on cryptography, which is the backbone of secure communication in the digital age. The unique properties of quantum mechanics allow quantum computers to perform certain calculations much more efficiently than classical computers, leading to significant implications for various cryptographic protocols. Below is a comprehensive analysis of this impact:\\n\\n### 1. Quantum Computing Fundamentals\\n\\n**Quantum Bits (Qubits):**\\n- Unlike classical bits that can be either 0 or 1, qubits can exist in superpositions of states, allowing quantum computers to process a vast amount of information simultaneously.\\n\\n**Quantum Algorithms:**\\n- The most notable algorithms impacting cryptography include:\\n  - **Shor’s Algorithm:** Efficiently factors large integers, threatening RSA and ECC (Elliptic Curve Cryptography).\\n  - **Grover’s Algorithm:** Provides a quadratic speedup for unstructured search problems, impacting symmetric cryptographic algorithms.\\n\\n### 2. Immediate Threats to Current Cryptographic Systems\\n\\n**Public-Key Cryptography:**\\n- **RSA and ECC Vulnerability:** \\n  - RSA relies on the difficulty of factoring large prime numbers, while ECC relies on the difficulty of solving the discrete logarithm problem. Both are rendered insecure by Shor's algorithm, which can factor integers and compute discrete logarithms in polynomial time. This means that any system relying on these algorithms could be compromised by a sufficiently powerful quantum computer.\\n\\n**Symmetric Cryptography:**\\n- **Impact on AES and Hash Functions:**\\n  - Grover's algorithm can effectively halve the security level of symmetric key algorithms. For example, AES-256 would offer security equivalent to AES-128 against quantum attacks. This necessitates longer key lengths to maintain security in a post-quantum world.\\n\\n### 3. Transition to Post-Quantum Cryptography\\n\\n**Post-Quantum Cryptography (PQC):**\\n- Researchers are developing cryptographic algorithms that are believed to be secure against quantum attacks. The National Institute of Standards and Technology (NIST) is leading efforts to standardize PQC algorithms.\\n\\n**Candidates for PQC:**\\n- **Lattice-Based Cryptography:** Based on problems like the Shortest Vector Problem (SVP) and Learning With Errors (LWE), these schemes are believed to be resistant to quantum attacks.\\n- **Hash-Based Signatures:** Utilizes hash functions to create secure digital signatures, offering a strong alternative.\\n- **Multivariate Quadratic Equations:** Relies on the difficulty of solving systems of multivariate quadratic equations.\\n\\n### 4. Implementation Challenges\\n\\n**Adoption and Migration:**\\n- Transitioning from current cryptographic systems to post-quantum ones poses challenges, including:\\n  - **Backward Compatibility:** Ensuring new systems can work with existing infrastructure.\\n  - **Performance Issues:** New algorithms may have different performance characteristics, impacting latency and resource usage.\\n  - **Standardization and Trust:** The new algorithms need to be vetted and standardized to build trust within the community.\\n\\n**Infrastructure Overhaul:**\\n- Systems and protocols (like TLS, VPNs, and digital signatures) that rely on vulnerable cryptographic schemes need significant updates or replacements.\\n\\n### 5. Long-Term Considerations\\n\\n**Quantum Key Distribution (QKD):**\\n- QKD leverages principles of quantum mechanics to create secure keys that are theoretically immune to eavesdropping. While promising, practical implementation faces challenges such as distance limitations and infrastructure cost.\\n\\n**Quantum-Resistant Protocols:**\\n- The development of communication protocols that can withstand quantum attacks is crucial. These include utilizing hybrid approaches that combine classical and quantum-resistant algorithms.\\n\\n### 6. Societal and Economic Implications\\n\\n**Impact on Security:**\\n- The potential for quantum computers to break current cryptographic systems raises concerns about the security of sensitive data, including financial transactions and personal information.\\n\\n**Economic Factors:**\\n- Organizations may need to invest heavily in the migration to post-quantum cryptography, which could affect budgets and resource allocation.\\n\\n### 7. Future Directions\\n\\n- **Research and Development:** Continued investment in both quantum computing and post-quantum cryptography research is critical to stay ahead of potential threats.\\n- **Education and Awareness:** Raising awareness among stakeholders about the implications of quantum computing on security practices is essential.\\n\\n### Conclusion\\n\\nQuantum computing represents both a threat and an opportunity for the field of cryptography. While existing systems face significant vulnerabilities, the rise of post-quantum cryptography offers a pathway to secure communications in a quantum-enabled future. The transition will require careful planning, investment, and collaboration across the cryptography community, industry stakeholders, and policy-makers to ensure that security is maintained in the face of evolving technological capabilities.\", 'usage': {'input_tokens': 19, 'output_tokens': 942, 'total_tokens': 961}}\n",
      "2025-01-24 20:55:10,050 - INFO - Added input cost: $0.0000, output cost: $0.0006, total: $0.0006. Running total: input $0.0011, output $0.2337, total $0.2347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Quantum computing is poised to have a profound impact on cryptography, which is the backbone of secure communication in the digital age. The unique properties of quantum mechanics allow quantum computers to perform certain calculations much more efficiently than classical computers, leading to significant implications for various cryptographic protocols. Below is a comprehensive analysis of this impact:\n",
      "\n",
      "### 1. Quantum Computing Fundamentals\n",
      "\n",
      "**Quantum Bits (Qubits):**\n",
      "- Unlike classical bits that can be either 0 or 1, qubits can exist in superpositions of states, allowing quantum computers to process a vast amount of information simultaneously.\n",
      "\n",
      "**Quantum Algorithms:**\n",
      "- The most notable algorithms impacting cryptography include:\n",
      "  - **Shor’s Algorithm:** Efficiently factors large integers, threatening RSA and ECC (Elliptic Curve Cryptography).\n",
      "  - **Grover’s Algorithm:** Provides a quadratic speedup for unstructured search problems, impacting symmetric cryptographic algorithms.\n",
      "\n",
      "### 2. Immediate Threats to Current Cryptographic Systems\n",
      "\n",
      "**Public-Key Cryptography:**\n",
      "- **RSA and ECC Vulnerability:** \n",
      "  - RSA relies on the difficulty of factoring large prime numbers, while ECC relies on the difficulty of solving the discrete logarithm problem. Both are rendered insecure by Shor's algorithm, which can factor integers and compute discrete logarithms in polynomial time. This means that any system relying on these algorithms could be compromised by a sufficiently powerful quantum computer.\n",
      "\n",
      "**Symmetric Cryptography:**\n",
      "- **Impact on AES and Hash Functions:**\n",
      "  - Grover's algorithm can effectively halve the security level of symmetric key algorithms. For example, AES-256 would offer security equivalent to AES-128 against quantum attacks. This necessitates longer key lengths to maintain security in a post-quantum world.\n",
      "\n",
      "### 3. Transition to Post-Quantum Cryptography\n",
      "\n",
      "**Post-Quantum Cryptography (PQC):**\n",
      "- Researchers are developing cryptographic algorithms that are believed to be secure against quantum attacks. The National Institute of Standards and Technology (NIST) is leading efforts to standardize PQC algorithms.\n",
      "\n",
      "**Candidates for PQC:**\n",
      "- **Lattice-Based Cryptography:** Based on problems like the Shortest Vector Problem (SVP) and Learning With Errors (LWE), these schemes are believed to be resistant to quantum attacks.\n",
      "- **Hash-Based Signatures:** Utilizes hash functions to create secure digital signatures, offering a strong alternative.\n",
      "- **Multivariate Quadratic Equations:** Relies on the difficulty of solving systems of multivariate quadratic equations.\n",
      "\n",
      "### 4. Implementation Challenges\n",
      "\n",
      "**Adoption and Migration:**\n",
      "- Transitioning from current cryptographic systems to post-quantum ones poses challenges, including:\n",
      "  - **Backward Compatibility:** Ensuring new systems can work with existing infrastructure.\n",
      "  - **Performance Issues:** New algorithms may have different performance characteristics, impacting latency and resource usage.\n",
      "  - **Standardization and Trust:** The new algorithms need to be vetted and standardized to build trust within the community.\n",
      "\n",
      "**Infrastructure Overhaul:**\n",
      "- Systems and protocols (like TLS, VPNs, and digital signatures) that rely on vulnerable cryptographic schemes need significant updates or replacements.\n",
      "\n",
      "### 5. Long-Term Considerations\n",
      "\n",
      "**Quantum Key Distribution (QKD):**\n",
      "- QKD leverages principles of quantum mechanics to create secure keys that are theoretically immune to eavesdropping. While promising, practical implementation faces challenges such as distance limitations and infrastructure cost.\n",
      "\n",
      "**Quantum-Resistant Protocols:**\n",
      "- The development of communication protocols that can withstand quantum attacks is crucial. These include utilizing hybrid approaches that combine classical and quantum-resistant algorithms.\n",
      "\n",
      "### 6. Societal and Economic Implications\n",
      "\n",
      "**Impact on Security:**\n",
      "- The potential for quantum computers to break current cryptographic systems raises concerns about the security of sensitive data, including financial transactions and personal information.\n",
      "\n",
      "**Economic Factors:**\n",
      "- Organizations may need to invest heavily in the migration to post-quantum cryptography, which could affect budgets and resource allocation.\n",
      "\n",
      "### 7. Future Directions\n",
      "\n",
      "- **Research and Development:** Continued investment in both quantum computing and post-quantum cryptography research is critical to stay ahead of potential threats.\n",
      "- **Education and Awareness:** Raising awareness among stakeholders about the implications of quantum computing on security practices is essential.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Quantum computing represents both a threat and an opportunity for the field of cryptography. While existing systems face significant vulnerabilities, the rise of post-quantum cryptography offers a pathway to secure communications in a quantum-enabled future. The transition will require careful planning, investment, and collaboration across the cryptography community, industry stakeholders, and policy-makers to ensure that security is maintained in the face of evolving technological capabilities.\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    details = llm_selector.get_complexity_details(prompt)\n",
    "    print(\"Complexity Details:\", details)\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm_selector.generate_response(prompt)\n",
    "    print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_cost': 0.0011, 'output_cost': 0.2337, 'total_cost': 0.2347}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_selector.cost_tracker.get_cost_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
