{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"src\"), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 21:17:34,277 - INFO - HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n",
      "/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.llm_selector.core import LLMSelector\n",
    "from src.config.settings import ModelConfig, DynamicLLMSelectorConfig\n",
    "from src.llm_selector.model_registry import ModelRegistry, ModelConfig\n",
    "from src.compression.openai import OpenaiCompressor\n",
    "from src.compression.gemini import GeminiCompressor\n",
    "from src.llm_selector.providers.openai import OpenAIProvider\n",
    "from src.llm_selector.providers.gemini import GeminiProvider\n",
    "from src.llm_selector.providers.anthropic import AnthropicProvider\n",
    "from src.complextiy.gemini import GeminiComplexityAnalyzer\n",
    "from src.complextiy.code import CodeComplexityAnalyzer\n",
    "from src.compression.code import CodeCompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "compressor = GeminiCompressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from typing import Dict, Any\n",
    "\n",
    "def load_yaml_files(directory: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load all YAML files from a given directory and return a unified dictionary.\n",
    "    \n",
    "    :param directory: Path to the directory containing YAML files.\n",
    "    :return: A dictionary containing the merged content of all YAML files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "    \n",
    "    unified_data = {}\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".yaml\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\") as yaml_file:\n",
    "                    try:\n",
    "                        # Load the content of the YAML file\n",
    "                        data = yaml.safe_load(yaml_file)\n",
    "                        if isinstance(data, dict):\n",
    "                            # Merge the loaded data into the unified dictionary\n",
    "                            unified_data.update(data)\n",
    "                        else:\n",
    "                            print(f\"Skipping {file_path}: Root element is not a dictionary.\")\n",
    "                    except yaml.YAMLError as e:\n",
    "                        print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    return unified_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openai_pricing': {'gpt_3_5_turbo': {'input': 0.0005, 'output': 0.0015}, 'gpt_3_5_turbo_16k': {'input': 0.003, 'output': 0.006}, 'gpt_4': {'input': 0.01, 'output': 0.03}, 'gpt_4_32k': {'input': 0.03, 'output': 0.06}, 'gpt_4o': {'input': 0.0025, 'output': 0.01}, 'gpt_4o_mini': {'input': 0.00015, 'output': 0.0006}, 'gpt_4_turbo': {'input': 0.01, 'output': 0.03}, 'o1': {'input': 0.015, 'output': 0.06}, 'o1_mini': {'input': 0.003, 'output': 0.012}, 'gpt_4o_realtime_preview': {'input': 0.005, 'output': 0.02}, 'gpt_4o_mini_realtime_preview': {'input': 0.0006, 'output': 0.0024}}, 'anthropic_pricing': {'claude_3_5_sonnet': {'context_window': 200000, 'input_cost_per_mtok': 3.0, 'output_cost_per_mtok': 15.0, 'prompt_caching_write': 3.75, 'prompt_caching_read': 0.3, 'notes': 'Most intelligent model, 50% discount with Batches API'}, 'claude_3_5_haiku': {'context_window': 200000, 'input_cost_per_mtok': 0.8, 'output_cost_per_mtok': 4.0, 'prompt_caching_write': 1.0, 'prompt_caching_read': 0.08, 'notes': 'Fastest and most cost-effective model, 50% discount with Batches API'}, 'claude_3_opus': {'context_window': 200000, 'input_cost_per_mtok': 15.0, 'output_cost_per_mtok': 75.0, 'prompt_caching_write': 18.75, 'prompt_caching_read': 1.5, 'notes': 'Powerful model for complex tasks, 50% discount with Batches API'}}, 'gemini_pricing': {'gemini_1_5_flash': {'input_pricing': {'below_128k': 7.5e-05, 'above_128k': 0.00015}, 'output_pricing': {'below_128k': 0.0003, 'above_128k': 0.0006}}, 'gemini_1_5_flash_8b': {'input_pricing': {'below_128k': 3.75e-05, 'above_128k': 7.5e-05}, 'output_pricing': {'below_128k': 0.00015, 'above_128k': 0.0003}}, 'gemini_1_5_pro': {'input_pricing': {'below_128k': 0.00125, 'above_128k': 0.0025}, 'output_pricing': {'below_128k': 0.005, 'above_128k': 0.01}}, 'gemini_1_0_pro': {'input_pricing': {'below_128k': 0.0005, 'above_128k': 0.001}, 'output_pricing': {'below_128k': 0.0015, 'above_128k': 0.003}}}}\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the YAML files\n",
    "directory = \"../src/config/pricing/\"\n",
    "\n",
    "# Load all YAML files\n",
    "all_pricing_data = load_yaml_files(directory)\n",
    "\n",
    "# Print the unified dictionary\n",
    "print(all_pricing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom configuration\n",
    "custom_config = DynamicLLMSelectorConfig(\n",
    "    models={\n",
    "        # Gemini models\n",
    "        \"gemini-1.5-flash\": ModelConfig(\n",
    "            name=\"gemini-1.5-flash\",\n",
    "            provider=\"gemini\",\n",
    "            complexity_threshold=20.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash\"][\"input_pricing\"][\"below_128k\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash\"][\"output_pricing\"][\"below_128k\"],\n",
    "            model_instance=GeminiProvider(\"gemini-1.5-flash\")\n",
    "        ),\n",
    "        # \"gemini-1.5-flash-8b\": ModelConfig(\n",
    "        #     name=\"gemini-1.5-flash-8b\",\n",
    "        #     provider=\"gemini\",\n",
    "        #     complexity_threshold=10.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash_8b\"][\"input_pricing\"][\"below_128k\"],\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_flash_8b\"][\"output_pricing\"][\"below_128k\"],\n",
    "        #     model_instance=GeminiProvider(\"gemini-1.5-flash-8b\")\n",
    "        # ),\n",
    "        # \"gemini-1.5-pro\": ModelConfig(\n",
    "        #     name=\"gemini-1.5-pro\",\n",
    "        #     provider=\"gemini\",\n",
    "        #     complexity_threshold=50.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_pro\"][\"input_pricing\"][\"below_128k\"],\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"gemini_pricing\"][\"gemini_1_5_pro\"][\"output_pricing\"][\"below_128k\"],\n",
    "        #     model_instance=GeminiProvider(\"gemini-1.5-pro\")\n",
    "        # ),\n",
    "\n",
    "        # OpenAI models\n",
    "        \"gpt-3.5-turbo\": ModelConfig(\n",
    "            name=\"gpt-3.5-turbo\",\n",
    "            provider=\"openai\",\n",
    "            complexity_threshold=40.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_3_5_turbo\"][\"input\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_3_5_turbo\"][\"output\"],\n",
    "            model_instance=OpenAIProvider(\"gpt-3.5-turbo\")\n",
    "        ),\n",
    "        \"gpt-4o-mini\": ModelConfig(\n",
    "            name=\"gpt-4o-mini\",\n",
    "            provider=\"openai\",\n",
    "            complexity_threshold=55.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_4o_mini\"][\"input\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_4o_mini\"][\"output\"],\n",
    "            model_instance=OpenAIProvider(\"gpt-4o-mini\")\n",
    "        ),\n",
    "        \"gpt-4\": ModelConfig(\n",
    "            name=\"gpt-4\",\n",
    "            provider=\"openai\",\n",
    "            complexity_threshold=75.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_4\"][\"input\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_4\"][\"output\"],\n",
    "            model_instance=OpenAIProvider(\"gpt-4\")\n",
    "        ),\n",
    "        # \"gpt-4-turbo\": ModelConfig(\n",
    "        #     name=\"gpt-4-turbo\",\n",
    "        #     provider=\"openai\",\n",
    "        #     complexity_threshold=80.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_4_turbo\"][\"input\"],\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_4_turbo\"][\"output\"],\n",
    "        #     model_instance=OpenAIProvider(\"gpt-4-turbo\")\n",
    "        # ),\n",
    "\n",
    "        # # Anthropic models\n",
    "        # \"claude-3.5-sonnet\": ModelConfig(\n",
    "        #     name=\"claude-3.5-sonnet\",\n",
    "        #     provider=\"anthropic\",\n",
    "        #     complexity_threshold=60.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_sonnet\"][\"input_cost_per_mtok\"] / 1000,\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_sonnet\"][\"output_cost_per_mtok\"] / 1000,\n",
    "        #     model_instance=AnthropicProvider(\"claude-3.5-sonnet\")\n",
    "        # ),\n",
    "        # \"claude-3.5-haiku\": ModelConfig(\n",
    "        #     name=\"claude-3.5-haiku\",\n",
    "        #     provider=\"anthropic\",\n",
    "        #     complexity_threshold=45.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_haiku\"][\"input_cost_per_mtok\"] / 1000,\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"anthropic_pricing\"][\"claude_3_5_haiku\"][\"output_cost_per_mtok\"] / 1000,\n",
    "        #     model_instance=AnthropicProvider(\"claude-3.5-haiku\")\n",
    "        # ),\n",
    "        # \"claude-3-opus\": ModelConfig(\n",
    "        #     name=\"claude-3-opus\",\n",
    "        #     provider=\"anthropic\",\n",
    "        #     complexity_threshold=85.0,\n",
    "        #     cost_per_1k_tokens_input=all_pricing_data[\"anthropic_pricing\"][\"claude_3_opus\"][\"input_cost_per_mtok\"] / 1000,\n",
    "        #     cost_per_1k_tokens_output=all_pricing_data[\"anthropic_pricing\"][\"claude_3_opus\"][\"output_cost_per_mtok\"] / 1000,\n",
    "        #     model_instance=AnthropicProvider(\"claude-3-opus\")\n",
    "        # )\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model registry\n",
    "model_registry = ModelRegistry()\n",
    "model_registry.register_models(custom_config.get_models_for_registry())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelConfig(name='gemini-1.5-flash', provider='gemini', complexity_threshold=20.0, cost_per_1k_tokens_input=7.5e-05, cost_per_1k_tokens_output=0.0003, api_key=None, model_instance=<src.llm_selector.providers.gemini.GeminiProvider object at 0x17a2d5840>),\n",
       " ModelConfig(name='gpt-3.5-turbo', provider='openai', complexity_threshold=40.0, cost_per_1k_tokens_input=0.0005, cost_per_1k_tokens_output=0.0015, api_key='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', model_instance=<src.llm_selector.providers.openai.OpenAIProvider object at 0x17a2d51e0>),\n",
       " ModelConfig(name='gpt-4o-mini', provider='openai', complexity_threshold=55.0, cost_per_1k_tokens_input=0.00015, cost_per_1k_tokens_output=0.0006, api_key='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', model_instance=<src.llm_selector.providers.openai.OpenAIProvider object at 0x17a2d5180>),\n",
       " ModelConfig(name='gpt-4', provider='openai', complexity_threshold=75.0, cost_per_1k_tokens_input=0.01, cost_per_1k_tokens_output=0.03, api_key='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', model_instance=<src.llm_selector.providers.openai.OpenAIProvider object at 0x17a2d5120>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_registry.get_sorted_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM Selector with custom configuration\n",
    "llm_selector = LLMSelector(model_registry=model_registry, compression=compressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test cases\n",
    "prompts = [\n",
    "    # Lovable.dev prompts\n",
    "    \"\"\"An app for salads business online.\n",
    "Name: Leaf & Grain\n",
    "Background: leafy green and millets and grains(green and beige)\n",
    "\n",
    "2 Options\n",
    "Option 1 : Made For you\n",
    "Option 2: Build your Bowl\n",
    "made of you page has 3 selection .Bowl size Small,Medium and Large with prefixed Menus of salads .\n",
    "Build Your Bowl \n",
    "Step 1:Customer opts for a size of the bowl.(Small,Med & large)(volume of bowls per Ingredient is Prefixed)\n",
    "Step 2:Select a Base of Available(ice burg Lettuce,Green Lettuce,Cabbage,brown Rice,Quinoa,Boiled millets and Sprouts)\n",
    "Step 3:Choice of other Veggies(Peppers,Red cabbage,Tomatoes,Cherry tomoatoes,Steamed Broccolli,Sweat Potato,celery,carrots,Beetroot,Apples,mushrooms,pineapples,etc.\n",
    "Step 4:top it up with choice of Sauces and mayo(All freshly made)or freshly made as per order.\n",
    "Step 5:Choice of Protien from Veg & non veg Options( Chicken,Lamb,Eggs,Soy,Boiled Chickpeas,Cottage cheese.\n",
    "Step 6:Top it off with a drizzle of Extra Virgin Olive Oil,Sesame Oil,virgin coconut oil and a dash of Sesame Seeds,Chai seeds,Tulasi Seeds,All seed mix(Flax seeds,Pumpkin,Sunflower).\n",
    "       Basil,corinander,mint,parsley.\n",
    "Salt,Pepper, Chilli Flakes,Vinegar(plain and Apple Cider),Oregano & Green chilli oil available for customers as Condiments.\n",
    "Customer selects the Bowl ,then customers has selection for base like rice ,Millets etc to select from.Then the Veggies base.\"\"\",\n",
    "    \"\"\"make these changes in the Made of you Tab.Option 1 : Made For you(customer has 3 option of Bowl select from. small,medium and large.once the selection is done the menu transits into the Names of salads Mentioned Below.\n",
    "Chicken satay salad,Crunchy chopped salad,Tuna, asparagus & white bean salad,Vegan roast spiced squash salad with tahini dressing,Giant couscous salad with charred veg & tangy pesto,Peanut lime salad,Lentil & tuna salad,Epic summer salad,Celery salad,Chickpea salad paste these with Pictures\"\"\"\n",
    "    \"\"\"Home Page Text\n",
    "Header Section\n",
    "Tagline:\n",
    "\"Build Connections That Matter â€“ Where Prestige Meets Opportunity.\"\n",
    "\n",
    "Subtext:\n",
    "Join a community of professionals driven by trust, integrity, and high achievement. Discover, connect, and grow like never before.\n",
    "\n",
    "Call-to-Action Buttons:\n",
    "\n",
    "[Get Started]\n",
    "[Explore Membership Options]\n",
    "Benefits Section\n",
    "Headline:\n",
    "\"Why Join Us?\"\n",
    "\n",
    "Bullet Points:\n",
    "\n",
    "ðŸŒŸ Exclusive Network: Connect with top professionals in your industry and location.\n",
    "ðŸ’¬ Meaningful Discussions: Join subject-based chats and forums tailored to your interests.\n",
    "ðŸ… Prestige & Rewards: Earn recognition and points for engagement, referrals, and contributions.\n",
    "ðŸ›¡ï¸ Privacy First: Complete control over your profile visibility and interactions.\n",
    "Membership Tiers Section\n",
    "Headline:\n",
    "\"Choose Your Membership Level\"\n",
    "\n",
    "Tiers:\n",
    "\n",
    "Basic â€“ Â£2/day\n",
    "\n",
    "Access to the community.\n",
    "Connect with users in your location.\n",
    "Pro â€“ Â£7/day\n",
    "\n",
    "All Basic features.\n",
    "Access exclusive professional events and industry discussions.\n",
    "Message and connect with higher-tier users.\n",
    "Elite â€“ Â£14/day\n",
    "\n",
    "All Pro features.\n",
    "Invitation-only connections and VIP events.\n",
    "Full visibility and networking with top-tier professionals.\n",
    "CTA Buttons for Each Tier:\n",
    "\n",
    "[Join Basic]\n",
    "[Upgrade to Pro]\n",
    "[Go Elite]\n",
    "Dynamic Section: Testimonials\n",
    "Headline:\n",
    "\"What Our Members Say\"\n",
    "\n",
    "\"This platform connected me with mentors I couldnâ€™t find elsewhere.\" â€“ Sarah, Tech Entrepreneur\n",
    "\"Finally, a network where quality outweighs quantity.\" â€“ James, Investment Banker\n",
    "Footer Section\n",
    "Links:\n",
    "About Us | Contact | Terms & Conditions | Privacy Policy\n",
    "Social Media: Icons for LinkedIn, Twitter, Instagram\n",
    "Tagline:\n",
    "\"Great leaders have great followers.\"\n",
    "Dynamic Website Instructions\n",
    "1. Membership Tier Selection\n",
    "Each membership tier button ([Join Basic], [Upgrade to Pro], [Go Elite]) should redirect to the registration page, passing the selected tier as a parameter.\n",
    "Example URL: /register?tier=basic\n",
    "On the registration page:\n",
    "Display the selected membership tier.\n",
    "Allow users to change tiers before completing registration.\n",
    "Implementation:\n",
    "\n",
    "Frontend:\n",
    "Use React Router for navigation.\n",
    "Pass the selected tier as a query parameter.\n",
    "Backend:\n",
    "Store the tier in the user's profile once registration is complete.\n",
    "Dynamic Text on Registration Page:\n",
    "\"Youâ€™ve selected the {tier} membership. Complete your registration to start networking!\"\n",
    "2. Personalized Home Page Content\n",
    "Logged-Out View:\n",
    "Show a static mock-up of the platform with general benefits and tier information.\n",
    "Logged-In View:\n",
    "Replace the homepage with a dashboard showing:\n",
    "Recommended connections (based on geolocation and industry).\n",
    "Discussion threads and events based on the user's interests.\n",
    "Their current membership tier and option to upgrade.\n",
    "Implementation:\n",
    "\n",
    "Use Supabaseâ€™s authentication status to check if the user is logged in.\n",
    "Redirect logged-in users to the dashboard.\n",
    "3. Dynamic Testimonials Section\n",
    "Rotate user testimonials dynamically.\n",
    "Use Supabase to store and fetch testimonials.\n",
    "Implementation:\n",
    "\n",
    "Supabase table:\n",
    "testimonials: id, user_name, testimonial_text, user_title\n",
    "Display a random testimonial using Supabaseâ€™s API:\n",
    "javascript\n",
    "Copy\n",
    "Edit\n",
    "const fetchTestimonial = async () => {\n",
    "  const { data, error } = await supabase.from('testimonials').select('*').limit(1).single();\n",
    "  if (data) setTestimonial(data);\n",
    "};\n",
    "4. Payment and Registration Integration\n",
    "Stripe Integration:\n",
    "Add a step on the registration page to process payments based on the selected tier.\n",
    "Once payment is successful, complete the user registration.\n",
    "Flow:\n",
    "\n",
    "User selects a tier and is redirected to /register.\n",
    "After filling out profile details, the user clicks Submit.\n",
    "Redirect to Stripe for payment.\n",
    "On payment success, save the userâ€™s data in the Supabase database and send a welcome email.\n",
    "Implementation:\n",
    "\n",
    "Frontend: Use Stripeâ€™s Checkout API for payment processing.\n",
    "Backend:\n",
    "Handle webhooks from Stripe to verify payments.\n",
    "Update the userâ€™s membership tier in the database.\"\"\",\n",
    "\"\"\"\n",
    "History\n",
    "### **Project Name:** Retro Basketball Scoreboard App  \n",
    "\n",
    "---\n",
    "\n",
    "### **Project Description:**  \n",
    "Develop a **Retro Basketball Scoreboard App** that immerses users in the classic vibe of old-school basketball scoreboards while providing robust functionality for real-time game tracking. The app will allow users to manage scores, fouls, timers, and player information, including substitutions, personal fouls, and individual performance metrics. A registration system for teams and players will enhance pre-game preparation.  \n",
    "\n",
    "The app will be highly interactive, featuring a nostalgic retro design with analog-inspired elements and engaging animations. All data will be managed locally in the browser without external database dependencies.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Features to Include:**  \n",
    "\n",
    "#### **1. Team and Player Registration**  \n",
    "- Users can **add teams** and input their **team names** dynamically.  \n",
    "- **Player registration for each team**, including:  \n",
    "  - **Player Name**  \n",
    "  - **Jersey Number**  \n",
    "  - Initial foul and score count set to 0.  \n",
    "- Display team rosters with all registered players before starting the game.  \n",
    "\n",
    "#### **2. Editable Team and Player Information**  \n",
    "- Allow users to edit:  \n",
    "  - **Team names**  \n",
    "  - **Player information** (e.g., name, jersey number).  \n",
    "- Real-time updates to reflect changes in the scoreboard interface.  \n",
    "\n",
    "#### **3. Scoring System**  \n",
    "- Track individual and team scores:  \n",
    "  - **+1 Point Button** for individual players.  \n",
    "  - Team score automatically updates based on individual scores.  \n",
    "- Animated score changes with retro flip-card effects.  \n",
    "\n",
    "#### **4. Foul Tracking**  \n",
    "- Track fouls at both **team** and **individual player** levels:  \n",
    "  - **Add Foul Button** for each player, updating personal and team fouls.  \n",
    "  - Notify users when a player accumulates **5 personal fouls**, suggesting substitution.  \n",
    "  - Highlight team fouls when they reach **5 total fouls**, with a retro buzzer effect.  \n",
    "- Visual indicators (e.g., flashing red for players at foul limits).  \n",
    "\n",
    "#### **5. Player Substitution**  \n",
    "- Allow users to substitute players:  \n",
    "  - Replace a fouled-out player with another registered player.  \n",
    "  - Substitute players can inherit the position while their stats reset or continue.  \n",
    "\n",
    "#### **6. Game Timer**  \n",
    "- Display a **retro game timer** with Start, Stop, and Reset controls:  \n",
    "  - Count in **mm:ss** format with an optional quarter indicator (e.g., Q1, Q2).  \n",
    "  - Styled in retro LED digits or analog clock visuals.  \n",
    "\n",
    "#### **7. Shot Clock**  \n",
    "- Include a **24-second shot clock**:  \n",
    "  - Resettable via a button with automatic reset after each scoring play.  \n",
    "  - Buzzer and visual indicator when the shot clock expires.  \n",
    "\n",
    "#### **8. Dynamic Team and Game Stats Display**  \n",
    "- Show team details with retro aesthetics:  \n",
    "  - Team names, total scores, and total fouls displayed prominently.  \n",
    "  - List of players for each team with:  \n",
    "    - Individual scores.  \n",
    "    - Jersey numbers.  \n",
    "    - Personal fouls.  \n",
    "\n",
    "#### **9. Responsive and Interactive UI**  \n",
    "- Large, easy-to-use buttons for actions like scoring, fouling, and substitutions.  \n",
    "- Retro design elements, including:  \n",
    "  - Flip animations for score updates.  \n",
    "  - LED-styled displays for timers and stats.  \n",
    "  - Tactile button press effects and vintage buzzer sounds.  \n",
    "- Dark mode toggle for evening games with glowing effects on UI elements.  \n",
    "\n",
    "#### **10. Offline Data Management**  \n",
    "- All game data stored locally in the browser using Web Storage (e.g., `localStorage`):  \n",
    "  - Persist data for team rosters, scores, and fouls until manually reset.  \n",
    "  - Allow users to reload or resume the app mid-game without data loss.  \n",
    "\n",
    "---\n",
    "\n",
    "### **UI/UX Design:**  \n",
    "\n",
    "#### **Retro Aesthetic:**  \n",
    "- **Color Scheme:** Warm tones (orange, brown, black) with contrasting white or cream accents.  \n",
    "- **Fonts:** Mimic classic scoreboard fonts with bold, clean readability.  \n",
    "- **Animations:** Smooth transitions for scoring, fouls, and timer updates, styled after vintage mechanical boards.  \n",
    "\n",
    "#### **Game Layout:**  \n",
    "- **Central Display:**  \n",
    "  - Team scores, total fouls, and game timer at the top.  \n",
    "  - Player stats displayed below, with individual fouls and scores clearly visible.  \n",
    "- **Shot Clock Placement:** Prominently displayed near the timer for quick visibility.  \n",
    "- **Buttons:** Large, tactile buttons for scoring and fouling, styled like physical controls.  \n",
    "\n",
    "#### **Responsive Design:**  \n",
    "- Scales across devices:  \n",
    "  - Mobile: Compact layout with swipe or tap functionality.  \n",
    "  - Desktop: Full-featured view with extra decorative elements.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Expected Output:**  \n",
    "A fully functional **Retro Basketball Scoreboard App** that combines the nostalgia of classic scoreboard designs with real-time game management. The app will be intuitive, visually engaging, and provide all essential tools for tracking and managing basketball games effectively. It will be a standalone solution, perfect for amateur leagues, school games, or casual basketball events.  \"\"\",\n",
    "\n",
    "    # Tabnine use cases\n",
    "    \"def quicksort(arr):\\n    \\\"\\\"\\\"Perform a quicksort on a list.\\n\\n    Args:\\n        arr (list): List to sort.\\n\\n    Returns:\\n        list: Sorted list.\\n    \\\"\\\"\\\"\\n    if len(arr) <= 1:\\n        return arr\\n    pivot = arr[len(arr) // 2]\\n    left = [x for x in arr if x < pivot]\\n    middle = [x for x in arr if x == pivot]\\n    right = [x for x in arr if x > pivot]\\n    return quicksort(left) + middle + quicksort(right)\",\n",
    "\n",
    "    \"class Node:\\n    def __init__(self, data):\\n        self.data = data\\n        self.next = None\\n\\nclass LinkedList:\\n    def __init__(self):\\n        self.head = None\\n\\n    def insert(self, data):\\n        new_node = Node(data)\\n        new_node.next = self.head\\n        self.head = new_node\\n\\n    def print_list(self):\\n        current = self.head\\n        while current:\\n            print(current.data)\\n            current = current.next\",\n",
    "\n",
    "    \"import React from 'react';\\n\\nfunction App() {\\n  const [count, setCount] = React.useState(0);\\n\\n  return (\\n    <div>\\n      <p>You clicked {count} times</p>\\n      <button onClick={() => setCount(count + 1)}>Click me</button>\\n    </div>\\n  );\\n}\\n\\nexport default App;\",\n",
    "\n",
    "    \"CREATE TABLE Users (\\n    ID INT PRIMARY KEY AUTO_INCREMENT,\\n    Username VARCHAR(50) NOT NULL,\\n    PasswordHash CHAR(64) NOT NULL,\\n    CreatedAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n);\",\n",
    "\n",
    "    \"from sklearn.linear_model import LinearRegression\\nimport numpy as np\\n\\n# Create data\\nX = np.array([[1], [2], [3], [4]])\\ny = np.array([2.5, 3.6, 4.5, 5.1])\\n\\n# Fit model\\nmodel = LinearRegression()\\nmodel.fit(X, y)\\n\\n# Predict\\nprint(model.predict([[5]]))\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:25:47 - LiteLLM:INFO\u001b[0m: utils.py:2825 - \n",
      "LiteLLM completion() model= gemini-pro; provider = gemini\n",
      "2025-01-26 21:25:47,100 - INFO - \n",
      "LiteLLM completion() model= gemini-pro; provider = gemini\n",
      "2025-01-26 21:25:53,644 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=AIzaSyANhhqv1XFG2icw4_Ntnv45HYFrSaJe-mw \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m21:25:53 - LiteLLM:INFO\u001b[0m: utils.py:1030 - Wrapper: Completed Call, calling success_handler\n",
      "2025-01-26 21:25:53,648 - INFO - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Union Types in TypeScript**\n",
      "\n",
      "Union types represent values that can be one of several possible types. They are declared using the pipe character (`|`) to separate the possible types.\n",
      "\n",
      "**Syntax:**\n",
      "\n",
      "```\n",
      "type UnionType = Type1 | Type2 | ... | TypeN;\n",
      "```\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Let's define a union type that can represent either a string or a number:\n",
      "\n",
      "```\n",
      "type StringOrNumber = string | number;\n",
      "```\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "Union types are useful in several scenarios:\n",
      "\n",
      "* **Representing multiple possible values:** Union types can express values that can be any of several types.\n",
      "* **Function signatures:** Union types can be used in function signatures to indicate that the function can accept different types of arguments.\n",
      "* **Property types:** Union types can be used to define the type of a property that can hold different types of values.\n",
      "* **Enforcing data validation:** Union types can help ensure that data is validated to a specific set of possible values.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "**Function Signature:**\n",
      "\n",
      "```\n",
      "function calculateArea(shape: Square | Rectangle): number {\n",
      "  // ...\n",
      "}\n",
      "```\n",
      "\n",
      "**Property Type:**\n",
      "\n",
      "```\n",
      "class Person {\n",
      "  name: string;\n",
      "  age: number | string;  // Can be either a number or a string\n",
      "}\n",
      "```\n",
      "\n",
      "**Data Validation:**\n",
      "\n",
      "```\n",
      "function validateInput(input: string | number): void {\n",
      "  if (typeof input === 'string') {\n",
      "    // Validate as a string\n",
      "  } else if (typeof input === 'number') {\n",
      "    // Validate as a number\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "**Advantages:**\n",
      "\n",
      "* **Increased flexibility:** Union types allow for versatile data structures that can handle multiple types of values.\n",
      "* **Improved code readability:** They make code more expressive and easier to understand.\n",
      "* **Enhanced type checking:** Union types provide better type safety by restricting values to specific types.\n",
      "\n",
      "**Limitations:**\n",
      "\n",
      "* **Limited type inference:** TypeScript cannot always infer the type of a variable or expression when using union types.\n",
      "* **Potential for type bloat:** Using union types excessively can lead to bulky code and performance overhead.\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def check_api_key():\n",
    "  \"\"\"\n",
    "  Check if the API key is available in the environment.\n",
    "  \"\"\"\n",
    "  api_key = os.environ.get('GEMINI_API_KEY')\n",
    "  if not api_key:\n",
    "    print(\"Please set the GEMINI_API_KEY environment variable with the API key.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "def chat(prompt: str) -> str:\n",
    "  \"\"\"\n",
    "  Generate a response from the model based on a given prompt.\n",
    "  \"\"\"\n",
    "  response = completion(\n",
    "    model=\"gemini/gemini-1.\", \n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  )\n",
    "  if response and response.choices:\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "  else:\n",
    "    return \"No response from the model\"\n",
    "\n",
    "\n",
    "check_api_key()\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Explain union types in TypeScript\"\n",
    "answer = chat(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-26 21:25:23,192 - INFO - Prompt complexity: 7.584962500721156\n",
      "2025-01-26 21:25:23,193 - INFO - Selected model: gemini-1.5-flash\n",
      "\u001b[92m21:25:23 - LiteLLM:INFO\u001b[0m: utils.py:2825 - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = vertex_ai\n",
      "2025-01-26 21:25:23,199 - INFO - \n",
      "LiteLLM completion() model= gemini-1.5-flash; provider = vertex_ai\n",
      "2025-01-26 21:25:23,216 - WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: [Errno 49] Can't assign requested address\n",
      "2025-01-26 21:25:24,257 - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 49] Can't assign requested address\n",
      "2025-01-26 21:25:26,372 - WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 49] Can't assign requested address\n",
      "2025-01-26 21:25:26,374 - WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.\n",
      "2025-01-26 21:25:26,381 - ERROR - Response generation error: litellm.APIConnectionError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/main.py\", line 2304, in completion\n",
      "    model_response = vertex_chat_completion.completion(  # type: ignore\n",
      "  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1204, in completion\n",
      "    _auth_header, vertex_project = self._ensure_access_token(\n",
      "  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 130, in _ensure_access_token\n",
      "    self._credentials, cred_project_id = self.load_auth(\n",
      "  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 84, in load_auth\n",
      "    creds, creds_project_id = google_auth.default(\n",
      "  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/google/auth/_default.py\", line 719, in default\n",
      "    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "litellm.APIConnectionError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\nTraceback (most recent call last):\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/main.py\", line 2304, in completion\n    model_response = vertex_chat_completion.completion(  # type: ignore\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1204, in completion\n    _auth_header, vertex_project = self._ensure_access_token(\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 130, in _ensure_access_token\n    self._credentials, cred_project_id = self.load_auth(\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 84, in load_auth\n    creds, creds_project_id = google_auth.default(\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/google/auth/_default.py\", line 719, in default\n    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\ngoogle.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/main.py:2304\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   2301\u001b[0m     litellm_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2302\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m litellm_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2303\u001b[0m ):\n\u001b[0;32m-> 2304\u001b[0m     model_response \u001b[38;5;241m=\u001b[39m \u001b[43mvertex_chat_completion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   2305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2309\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   2311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_ai_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2318\u001b[0m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[1;32m   2326\u001b[0m     \u001b[38;5;66;03m# Vertex Model Garden - OpenAI compatible models\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:1204\u001b[0m, in \u001b[0;36mVertexLLM.completion\u001b[0;34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[0m\n\u001b[1;32m   1200\u001b[0m should_use_v1beta1_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_using_v1beta1_features(\n\u001b[1;32m   1201\u001b[0m     optional_params\u001b[38;5;241m=\u001b[39moptional_params\n\u001b[1;32m   1202\u001b[0m )\n\u001b[0;32m-> 1204\u001b[0m _auth_header, vertex_project \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_access_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertex_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m auth_header, url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_token_and_url(\n\u001b[1;32m   1211\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1212\u001b[0m     gemini_api_key\u001b[38;5;241m=\u001b[39mgemini_api_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     should_use_v1beta1_features\u001b[38;5;241m=\u001b[39mshould_use_v1beta1_features,\n\u001b[1;32m   1221\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py:130\u001b[0m, in \u001b[0;36mVertexBase._ensure_access_token\u001b[0;34m(self, credentials, project_id, custom_llm_provider)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials, cred_project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_id:\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py:84\u001b[0m, in \u001b[0;36mVertexBase.load_auth\u001b[0;34m(self, credentials, project_id)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     creds, creds_project_id \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle_auth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://www.googleapis.com/auth/cloud-platform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m project_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/google/auth/_default.py:719\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 719\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi how are you?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/LLMOpt/src/llm_selector/core.py:85\u001b[0m, in \u001b[0;36mLLMSelector.generate_response\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m selected_model\u001b[38;5;241m.\u001b[39mmodel_instance:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model instance for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mselected_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse generated using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m usage \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/LLMOpt/src/llm_selector/providers/__init__.py:34\u001b[0m, in \u001b[0;36mBaseProvider.generate_with_metadata\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mGenerate a response for a given prompt with metadata using liteLLM\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m:return: Dictionary containing generated response and metadata\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[0;32m---> 34\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39musage,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39musage\u001b[38;5;241m.\u001b[39mtotal_cost \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response\u001b[38;5;241m.\u001b[39musage, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_cost\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     44\u001b[0m }\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/utils.py:1100\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[1;32m   1097\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m   1098\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m   1099\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m-> 1100\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/utils.py:978\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/main.py:2981\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m   2979\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2980\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 2981\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2190\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[1;32m   2189\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[0;32m-> 2190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2192\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mLITELLM_EXCEPTION_TYPES:\n",
      "File \u001b[0;32m~/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2166\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[1;32m   2160\u001b[0m                 message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(exception_provider, error_str),\n\u001b[1;32m   2161\u001b[0m                 llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   2162\u001b[0m                 model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   2163\u001b[0m                 request\u001b[38;5;241m=\u001b[39moriginal_exception\u001b[38;5;241m.\u001b[39mrequest,\n\u001b[1;32m   2164\u001b[0m             )\n\u001b[1;32m   2165\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2166\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[1;32m   2167\u001b[0m                 message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2168\u001b[0m                     \u001b[38;5;28mstr\u001b[39m(original_exception), traceback\u001b[38;5;241m.\u001b[39mformat_exc()\n\u001b[1;32m   2169\u001b[0m                 ),\n\u001b[1;32m   2170\u001b[0m                 llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m   2171\u001b[0m                 model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   2172\u001b[0m                 request\u001b[38;5;241m=\u001b[39mhttpx\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m   2173\u001b[0m                     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2174\u001b[0m                 ),  \u001b[38;5;66;03m# stub the request\u001b[39;00m\n\u001b[1;32m   2175\u001b[0m             )\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2177\u001b[0m     \u001b[38;5;66;03m# LOGGING\u001b[39;00m\n\u001b[1;32m   2178\u001b[0m     exception_logging(\n\u001b[1;32m   2179\u001b[0m         logger_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2180\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   2185\u001b[0m     )\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: litellm.APIConnectionError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\nTraceback (most recent call last):\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/main.py\", line 2304, in completion\n    model_response = vertex_chat_completion.completion(  # type: ignore\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1204, in completion\n    _auth_header, vertex_project = self._ensure_access_token(\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 130, in _ensure_access_token\n    self._credentials, cred_project_id = self.load_auth(\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 84, in load_auth\n    creds, creds_project_id = google_auth.default(\n  File \"/Users/amirdor/Documents/LLMOpt/.venv/lib/python3.10/site-packages/google/auth/_default.py\", line 719, in default\n    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\ngoogle.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n"
     ]
    }
   ],
   "source": [
    "response = llm_selector.generate_response(\"hi how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_cost': 5.7e-05, 'output_cost': 0.00056, 'total_cost': 0.000617}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_selector.cost_tracker.get_cost_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    # print(f\"\\nPrompt: {prompt}\")\n",
    "    details = llm_selector.get_complexity_details(prompt)\n",
    "    # print(\"Complexity Details:\", details)\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm_selector.generate_response(prompt)\n",
    "    # print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_selector.cost_tracker.get_cost_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = ModelRegistry()\n",
    "mr.register_models([ModelConfig(\n",
    "            name=\"gpt-4\",\n",
    "            provider=\"openai\",\n",
    "            complexity_threshold=75.0,\n",
    "            cost_per_1k_tokens_input=all_pricing_data[\"openai_pricing\"][\"gpt_4\"][\"input\"],\n",
    "            cost_per_1k_tokens_output=all_pricing_data[\"openai_pricing\"][\"gpt_4\"][\"output\"],\n",
    "            model_instance=OpenAIProvider(\"gpt-4\")\n",
    "        )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_4o_only = LLMSelector(model_registry=mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    # print(f\"\\nPrompt: {prompt}\")\n",
    "    details = openai_4o_only.get_complexity_details(prompt)\n",
    "    # print(\"Complexity Details:\", details)\n",
    "    \n",
    "    # Generate response\n",
    "    response = openai_4o_only.generate_response(prompt)\n",
    "    # print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_4o_only.cost_tracker.get_cost_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_selector_no_compressor = LLMSelector(model_registry=model_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    # print(f\"\\nPrompt: {prompt}\")\n",
    "    details = llm_selector_no_compressor.get_complexity_details(prompt)\n",
    "    # print(\"Complexity Details:\", details)\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm_selector_no_compressor.generate_response(prompt)\n",
    "    # print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_selector_no_compressor.cost_tracker.get_cost_breakdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
